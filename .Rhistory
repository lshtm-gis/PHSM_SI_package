group_by(person) %>%
summarize(total = sum(n))
View(total_words)
words <- left_join(words, total_words)
View(words)
words <- debateData %>%
unnest_tokens(word, dialogue) %>%
count(person,word, sort = TRUE) %>%
ungroup()
View(words)
total_words <- words %>%
group_by(person) %>%
summarize(total = sum(n))
View(total_words)
?left_join
View(words)
words <- left_join(words, total_words)
View(words)
View(total_words)
View(words)
freq_by_rank <- words %>%
group_by(person) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
View(freq_by_rank)
freq_by_rank
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank
freq_by_rank
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10() +
scale_y_log10()
rank_subset <- freq_by_rank %>%
filter(rank < 500,
rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
rank_subset <- freq_by_rank %>%
filter(rank < 500,
rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = book)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10() +
scale_y_log10()
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = TRUE) +
scale_x_log10() +
scale_y_log10()
rank_subset <- freq_by_rank %>%
filter(rank < 500,rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
rank_subset <- freq_by_rank %>%
filter(rank < 500,rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = person)) +
geom_abline(intercept = -0.8, slope = -1.0, color = "gray50", linetype = 2) +
geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) +
scale_x_log10() +
scale_y_log10()
q()
install.packages(c("hms", "ISOcodes", "lubridate", "pkgload", "rmarkdown", "RMySQL", "rtweet", "SnowballC", "stopwords", "textshape", "tidytext"))
install.packages('backports')
install.packages(c("hms", "ISOcodes", "lubridate", "pkgload", "rmarkdown", "Rmpi", "RMySQL", "rtweet", "SnowballC", "stopwords", "textshape", "tidytext"))
remove.packages("Rmpi", lib="~/R/x86_64-pc-linux-gnu-library/3.6")
remove.packages("doMPI", lib="/usr/local/lib/R/site-library")
remove.packages("doMPI", lib="/usr/local/lib/R/site-library")
remove.packages("doMPI", lib="/usr/local/lib/R/site-library")
remove.packages("doMPI", lib="/usr/local/lib/R/site-library")
remove.packages("doMPI", lib="/usr/local/lib/R/site-library")
installed.packages('Rmpi')
library('Rmpi')
install.packages('Rmpi')
install.packages("rlecuyer")
install.packages("fields")
install.packages("Rmpi")
q()
q()
install.packages("plotKML")
install.packages("viridis")
install.packages("xgboost")
install.packages("GSIF")
install.packages("Cubist")
install.packages("caret")
install.packages("raster")
install.packages("plyr")
install.packages("e1071")
install.packages("nnet")
library(plotKML)
library(nnet)
library(e1071)
library(GSIF)
library(plyr)
library(raster)
library(caret)
library(Cubist)
library(xgboost)
library(viridis)
data(eberg)
data(eberg_grid)
coordinates(eberg) <- ~X+Y
proj4string(eberg) <- CRS("+init=epsg:31467")
gridded(eberg_grid) <- ~x+y
proj4string(eberg_grid) <- CRS("+init=epsg:31467")
eberg_spc <- spc(eberg_grid, ~ PRMGEO6+DEMSRT6+TWISRT6+TIRAST6)
#> Converting PRMGEO6 to indicators...
#> Converting covariates to principal components...
eberg_grid@data <- cbind(eberg_grid@data, eberg_spc@predicted@data)
ov <- over(eberg, eberg_grid)
m <- cbind(ov, eberg@data)
dim(m)
xg <- summary(m$TAXGRSC, maxsum=(1+length(levels(m$TAXGRSC))))
str(xg)
selg.levs <- attr(xg, "names")[xg > 5]
attr(xg, "names")[xg <= 5]
m$soiltype <- m$TAXGRSC
m$soiltype[which(!m$TAXGRSC %in% selg.levs)] <- NA
m$soiltype <- droplevels(m$soiltype)
str(summary(m$soiltype, maxsum=length(levels(m$soiltype))))
m <- m[complete.cases(m[,1:(ncol(eberg_grid)+2)]),]
m$soiltype <- as.factor(m$soiltype)
summary(m$soiltype)
s <- sample.int(nrow(m), 500)
TAXGRSC.rf <- randomForest(x=m[-s,paste0("PC",1:10)], y=m$soiltype[-s],
xtest=m[s,paste0("PC",1:10)], ytest=m$soiltype[s])
library(randomForest)
TAXGRSC.rf <- randomForest(x=m[-s,paste0("PC",1:10)], y=m$soiltype[-s],
xtest=m[s,paste0("PC",1:10)], ytest=m$soiltype[s])
TAXGRSC.rf$test$confusion[,"class.error"]
TAXGRSC.rf <- randomForest(x=m[,paste0("PC",1:10)], y=m$soiltype)
fm <- as.formula(paste("soiltype~", paste(paste0("PC",1:10), collapse="+")))
TAXGRSC.mn <- nnet::multinom(fm, m)
TAXGRSC.svm <- e1071::svm(fm, m, probability=TRUE, cross=5)
TAXGRSC.svm$tot.accuracy
probs1 <- predict(TAXGRSC.mn, eberg_grid@data, type="probs", na.action = na.pass)
probs2 <- predict(TAXGRSC.rf, eberg_grid@data, type="prob", na.action = na.pass)
probs3 <- attr(predict(TAXGRSC.svm, eberg_grid@data,
probability=TRUE, na.action = na.pass), "probabilities")
leg <- levels(m$soiltype)
lt <- list(probs1[,leg], probs2[,leg], probs3[,leg])
probs <- Reduce("+", lt) / length(lt)
## copy and make new raster object:
eberg_soiltype <- eberg_grid
eberg_soiltype@data <- data.frame(probs)
ch <- rowSums(eberg_soiltype@data)
summary(ch)
plot(raster::stack(eberg_soiltype), col=SAGA_pal[[10]], zlim=c(0,1))
eberg_soiltype$cl <- as.factor(apply(eberg_soiltype@data,1,which.max))
levels(eberg_soiltype$cl) = attr(probs, "dimnames")[[2]][as.integer(levels(eberg_soiltype$cl))]
summary(eberg_soiltype$cl)
library(h2o)
localH2O = h2o.init(startH2O=TRUE)
eberg.hex <- as.h2o(m, destination_frame = "eberg.hex")
eberg.grid <- as.h2o(eberg_grid@data, destination_frame = "eberg.grid")
RF.m <- h2o.randomForest(y = which(names(m)=="SNDMHT_A"),
x = which(names(m) %in% paste0("PC",1:10)),
training_frame = eberg.hex, ntree = 50)
RF.m
library(scales)
library(lattice)
SDN.pred <- as.data.frame(h2o.predict(RF.m, eberg.hex, na.action=na.pass))$predict
plt1 <- xyplot(m$SNDMHT_A ~ SDN.pred, asp=1,
par.settings=list(
plot.symbol = list(col=scales::alpha("black", 0.6),
fill=scales::alpha("red", 0.6), pch=21, cex=0.8)),
ylab="measured", xlab="predicted (machine learning)")
knitr::include_graphics("figures/Measured_vs_predicted_SAND_plot.png")
plt1
eberg_grid$RFx <- as.data.frame(h2o.predict(RF.m, eberg.grid, na.action=na.pass))$predict
plot(raster(eberg_grid["RFx"]), col=rev(viridis(10)), zlim=c(10,90))
points(eberg, pch=21, cex=.7)
plot(raster(eberg_grid["RFx"]), col=rev(viridis(10)), zlim=c(10,90))
points(eberg, pch=21, cex=.2)
library(GSIF)
data(edgeroi)
edgeroi.sp = edgeroi$sites
coordinates(edgeroi.sp) <- ~ LONGDA94 + LATGDA94
proj4string(edgeroi.sp) <- CRS("+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
edgeroi.sp <- spTransform(edgeroi.sp, CRS("+init=epsg:28355"))
load("extdata/edgeroi.grids.rda")
gridded(edgeroi.grids) <- ~x+y
proj4string(edgeroi.grids) <- CRS("+init=epsg:28355")
names(edgeroi.grids)
load("extdata/edgeroi.grids.rda")
plot(raster::stack(eberg_soiltype@data), col=SAGA_pal[[10]], zlim=c(0,1))
library(GSIF)
data(edgeroi)
edgeroi.sp = edgeroi$sites
coordinates(edgeroi.sp) <- ~ LONGDA94 + LATGDA94
proj4string(edgeroi.sp) <- CRS("+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs")
edgeroi.sp <- spTransform(edgeroi.sp, CRS("+init=epsg:28355"))
getwd()
load("edgeroi.grids.rda")
gridded(edgeroi.grids) <- ~x+y
proj4string(edgeroi.grids) <- CRS("+init=epsg:28355")
names(edgeroi.grids)
edgeroi.spc = spc(edgeroi.grids, ~DEMSRT5+TWISRT5+PMTGEO5+EV1MOD5+EV2MOD5+EV3MOD5)
sg <- list.files("extdata", "edgeroi_sol_bulkdens.fineearth", full.names = TRUE)
ov <- as.data.frame(raster::extract(stack(sg), edgeroi.sp)*10)
ov.edgeroi.BLD = ov[,c(grep("b0..", names(ov),
fixed = TRUE), grep("b10..", names(ov), fixed = TRUE),
grep("b30..", names(ov),
fixed = TRUE), grep("b60..", names(ov), fixed = TRUE),
grep("b100..", names(ov),
fixed = TRUE), grep("b200..", names(ov), fixed = TRUE))]
ov.edgeroi.BLDm  <- data.frame(BLD.f = as.vector(sapply(2:ncol(ov.edgeroi.BLD),
function(i){rowMeans(ov.edgeroi.BLD[,c(i-1,i)])})),
DEPTH.c = as.vector(sapply(1:5, function(i){rep(paste0("sd",i),
nrow(edgeroi$sites))})), SOURCEID = rep(edgeroi$sites$SOURCEID, 5)
)
str(ov.edgeroi.BLDm)
edgeroi$horizons$DEPTH = edgeroi$horizons$UHDICM +
(edgeroi$horizons$LHDICM - edgeroi$horizons$UHDICM)/2
edgeroi$horizons$DEPTH.c = cut(edgeroi$horizons$DEPTH, include.lowest = TRUE,
breaks = c(0,10,30,60,100,1000), labels = paste0("sd",1:5))
summary(edgeroi$horizons$DEPTH.c)
edgeroi$horizons$BLD.f = plyr::join(edgeroi$horizons[,c("SOURCEID","DEPTH.c")],
ov.edgeroi.BLDm)$BLD.f
edgeroi$horizons$OCD = edgeroi$horizons$ORCDRC/1000 * edgeroi$horizons$BLD.f
summary(edgeroi$horizons$OCD)
ov2 <- over(edgeroi.sp, edgeroi.spc@predicted)
ov2$SOURCEID = edgeroi.sp$SOURCEID
h2 = hor2xyd(edgeroi$horizons)
m2 <- plyr::join_all(dfs = list(edgeroi$sites, h2, ov2))
leg = c("#0000ff", "#0028d7", "#0050af", "#007986", "#00a15e", "#00ca35", "#00f20d",
"#1aff00", "#43ff00", "#6bff00", "#94ff00", "#bcff00", "#e5ff00", "#fff200",
"#ffca00", "#ffa100", "#ff7900", "#ff5000", "#ff2800", "#ff0000")
hor2xyd = function(x, U="UHDICM", L="LHDICM", treshold.T=15){
x$DEPTH <- x[,U] + (x[,L] - x[,U])/2
x$THICK <- x[,L] - x[,U]
sel = x$THICK < treshold.T
## begin and end of the horizon:
x1 = x[!sel,]; x1$DEPTH = x1[,L]
x2 = x[!sel,]; x2$DEPTH = x1[,U]
y = do.call(rbind, list(x, x1, x2))
return(y)
}
ov2 <- over(edgeroi.sp, edgeroi.spc@predicted)
ov2$SOURCEID = edgeroi.sp$SOURCEID
h2 = hor2xyd(edgeroi$horizons)
m2 <- plyr::join_all(dfs = list(edgeroi$sites, h2, ov2))
fm.OCD = as.formula(paste0("OCD ~ DEPTH + ", paste(names(edgeroi.spc@predicted),
collapse = "+")))
fm.OCD
m.OCD <- ranger(fm.OCD, m2[complete.cases(m2[,all.vars(fm.OCD)]),],
quantreg = TRUE, importance = "impurity")
m.OCD
library(ranger)
fm.OCD = as.formula(paste0("OCD ~ DEPTH + ", paste(names(edgeroi.spc@predicted),
collapse = "+")))
fm.OCD
m.OCD <- ranger(fm.OCD, m2[complete.cases(m2[,all.vars(fm.OCD)]),],
quantreg = TRUE, importance = "impurity")
m.OCD
for(i in c(0,30)){
edgeroi.spc@predicted$DEPTH = i
OCD.rf <- predict(m.OCD, edgeroi.spc@predicted@data)
nm1 = paste0("OCD.", i, "cm")
edgeroi.grids@data[,nm1] = OCD.rf$predictions
OCD.qrf <- predict(m.OCD, edgeroi.spc@predicted@data,
type="quantiles", quantiles=c((1-.682)/2, 1-(1-.682)/2))
nm2 = paste0("OCD.", i, "cm_se")
edgeroi.grids@data[,nm2] = (OCD.qrf$predictions[,2] - OCD.qrf$predictions[,1])/2
}
library(raster)
edgeroi.grids$OCS.30cm = rowMeans(edgeroi.grids@data[,paste0("OCD.", c(0,30), "cm")]) * 0.3 * 10
summary(edgeroi.grids$OCS.30cm)
edgeroi.grids$OCS.30cm.f = ifelse(edgeroi.grids$OCS.30cm>76, 76, ifelse(edgeroi.grids$OCS.30cm<28, 28, edgeroi.grids$OCS.30cm))
## plot OCS 0-30 cm and the error map:
par(mfrow=c(1,2), oma=c(0,0,0,1), mar=c(0,0,3.5,1.5))
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "30 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
points(edgeroi.sp, pch=21, bg="white", cex=.8)
plot(raster(edgeroi.grids["OCD.30cm_se"])*0.3*10, col=rev(bpy.colors()), main="Standard prediction error (t/ha)", axes=FALSE, box=FALSE)
points(edgeroi.sp, pch=21, bg="white", cex=.8)
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "30 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
edgeroi.grids$OCS.30cm.f = ifelse(edgeroi.grids$OCS.30cm>76, 76, ifelse(edgeroi.grids$OCS.30cm<28, 28, edgeroi.grids$OCS.30cm))
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "30 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
points(edgeroi.sp, pch=21, bg="white", cex=.4)
points(edgeroi.sp, pch=20, bg="white", cex=.8)
points(edgeroi.sp, pch=21, bg="white", cex=.4)
points(edgeroi.sp, pch=21, bg="white", cex=.2)
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "30 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
points(edgeroi.sp, pch=21, bg="white", cex=.1)
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "30 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
points(edgeroi.sp, pch=21, bg="white", cex=.1)
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "10 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "10 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,76))
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "10 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,50))
plot(raster(edgeroi.grids["OCS.30cm.f"]), col=leg, main=paste0("Organic carbon stock 0", "\U2012", "10 cm (t/ha)"), axes=FALSE, box=FALSE, zlim=c(28,50))
plot(raster(eberg_grid["RFx"]), col=rev(viridis(10)), zlim=c(10,90))
> points(eberg, pch=21, cex=.2)
plot(raster(eberg_grid["RFx"]), col=rev(viridis(10)), zlim=c(10,90))
points(eberg, pch=21, cex=.2)
plot(raster(eberg_grid["RFx"]), col=rev(viridis(10)), zlim=c(10,90))
points(eberg, pch=21, cex=.2)
h2o.shutdown
h2o.shutdown(prompt = TRUE)
y
h2o.shutdown(prompt = TRUE)
h2o.shutdown(prompt = TRUE)
rm(list = ls())
clear()
clc
clr
q()
exit
q()
setwd("~/Documents/lshtm/severity_index/1803/PHSM_SI_package")
library(devtools)
load_all(".")
load_all(".")
library(tidyverse)
load_all(".")
load_all(".")
load_all(".")
?calc_sev
??calc_sev
aa <- dataprep('../1803/mistress_20210316.csv')
aa <- dataprep('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv')
View(aa)
library(roxygen2)
roxygenise()
?calc_sev
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv')
library(tidyverse)
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv')
library(lubridate)
library(cowplot)
library(rlist)
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv')
View(aa)
setwd("~/Documents/lshtm/severity_index/1803/PHSM_SI_package")
library(tidyverse)
library(lubridate)
library(rlist)
library(cowplot)
?forplot
load_all(".")
library(devtools)
load_all(".")
?forplot
setwd("~/Documents/lshtm/severity_index/1803/PHSM_SI_package",'Albania')
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv','Albania')
View(aa)
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv','France')
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv','France')
View(aa)
setwd("~/Documents/lshtm/severity_index/1803/PHSM_SI_package")
library(tidyverse)
library(lubridate)
library(cowplot)
library(rlist)
?dataprep
?dataprep.R
library(devtools)
load_all(".")
?dataprep.R
??dataprep.R
?dataprep
a1 <- dataprep('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv')
a2 <- binaryindex(a1)
View(a2)
a3<-ordmask(a2)
a3<-ordmasks(a2)
a4<-ordschools(a3)
a5<-ordbusiness(a4)
a6<-ordgather(a5)
a7<-ordmove(a6)
View(a7)
a8<-ordtravel(a7)
View(a8)
library(devtools)
load_all(".")
a88<-ordtravel(a7)
View(a88)
a9 <- calc_sev(a8)
View(a9)
View(a8)
View(a8)
View(a88)
library(devtools)
load_all(".")
a888<-ordtravel(a7)
View(a888)
library(devtools)
load_all(".")
a888<-ordtravel(a7)
View(a9)
a99 <- calc_sev(a888)
View(a99)
aa <- forplot('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_20210316.csv','France')
View(aa)
View(a99)
View(a99)
aa1 <- sevindex('/home/sewedo/Documents/lshtm/severity_index/1803/mistress_202103161.csv','France')
View(aa1)
#
# Get the minimum date in data and create a DF of dates
# from min date to current date
#
x <- aa1
x$date_start <- lubridate::ymd(x$date_start)
x <- x[order(as.Date(x$date_start, format="%Y-%m-%d")),]
start_date <- min(x$date_start, na.rm = TRUE)
today <- Sys.Date()
n_days <- interval(start_date,today)/days(1)
date <- start_date + days(0:n_days)
date <- as.data.frame(date)
date <- date %>% dplyr::rename(date_start = date)
print(paste0("Start date in data is: ", start_date))
y <- x %>%
filter (country_territory_area == country) %>%
group_by(date_start,category) %>%
pivot_wider(names_from = category, values_from = SI)
y$date_start <- lubridate::ymd(y$date_start)
y <- x %>%
filter (country_territory_area == 'France') %>%
group_by(date_start,category) %>%
pivot_wider(names_from = category, values_from = SI)
y$date_start <- lubridate::ymd(y$date_start)
y = y[order(as.Date(y$date_start, format="%Y-%m-%d")),]
y <- arrange(y, date_start) %>%
right_join(date)
y = y[order(as.Date(y$date_start, format="%Y-%m-%d")),]
cols <- c(Mask = NA_real_, School = NA_real_, Business = NA_real_,
Gatherings = NA_real_, Movements = NA_real_, Travel = NA_real_)
y <- add_column(y, !!!cols[setdiff(names(cols), names(y))])
y <- y %>%
group_by(date_start, country_territory_area) %>%
summarise(Mask =
ifelse(!is.null(Mask), max(as.numeric(Mask)),""),
Business =
ifelse(!is.null(Business), max(as.numeric(Business)),""),
Gathering =
ifelse(!is.null(Gatherings), max(as.numeric(Gatherings)),""),
School =
ifelse(!is.null(School), max(as.numeric(School)),""),
Movement =
ifelse(!is.null(Movements), max(as.numeric(Movements)),""),
Travel =
ifelse(!is.null(Travel), max(as.numeric(Travel)),""),
Binary =
ifelse(!is.null(binary), max(as.numeric(binary)),""),
Ordinal =
ifelse(!is.null(ordinal), max(as.numeric(ordinal)),""))
########################
write.csv(y,file='y.csv', row.names=FALSE)
y <- read.csv('y.csv')
#######################
y <- y %>%
dplyr::arrange(date_start) %>%
fill(country_territory_area,.direction = "downup") %>%
fill(Binary) %>%
fill(Ordinal) %>%
fill(School) %>%
fill(Gathering) %>%
fill(Movement) %>%
fill(Business) %>%
fill(Mask) %>%
fill(Travel) %>%
replace(is.na(.),0)
View(y)
